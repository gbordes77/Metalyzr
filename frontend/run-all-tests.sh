#!/bin/bash

echo "üöÄ METALYZR - Suite de Tests Compl√®te et Validation"
echo "================================================="

# Couleurs
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
NC='\033[0m'

# Variables globales
TOTAL_PHASES=6
CURRENT_PHASE=0
OVERALL_SUCCESS=true

# Fonctions utilitaires
log() {
    echo -e "${BLUE}[$(date +'%H:%M:%S')]${NC} $1"
}

success() {
    echo -e "${GREEN}‚úÖ $1${NC}"
}

error() {
    echo -e "${RED}‚ùå $1${NC}"
    OVERALL_SUCCESS=false
}

warning() {
    echo -e "${YELLOW}‚ö†Ô∏è  $1${NC}"
}

info() {
    echo -e "${PURPLE}‚ÑπÔ∏è  $1${NC}"
}

start_phase() {
    ((CURRENT_PHASE++))
    echo ""
    echo -e "${PURPLE}üìã Phase $CURRENT_PHASE/$TOTAL_PHASES: $1${NC}"
    echo "$(printf '=%.0s' {1..50})"
}

# V√©rification de l'environnement
check_environment() {
    start_phase "V√©rification de l'environnement"
    
    # V√©rifier qu'on est dans le bon dossier
    if [ ! -f "package.json" ]; then
        error "package.json non trouv√©. Ex√©cutez depuis le dossier frontend/"
        exit 1
    fi
    
    # V√©rifier Node.js
    if ! command -v node &> /dev/null; then
        error "Node.js non install√©"
        exit 1
    fi
    success "Node.js trouv√©: $(node --version)"
    
    # V√©rifier npm
    if ! command -v npm &> /dev/null; then
        error "npm non install√©"
        exit 1
    fi
    success "npm trouv√©: $(npm --version)"
    
    # V√©rifier Python
    if ! command -v python3 &> /dev/null; then
        warning "Python3 non trouv√© - tests serveur Python ignor√©s"
    else
        success "Python3 trouv√©: $(python3 --version)"
    fi
    
    # V√©rifier les d√©pendances
    if [ ! -d "node_modules" ]; then
        log "Installation des d√©pendances npm..."
        npm install
    fi
    success "D√©pendances npm pr√©sentes"
}

# Phase 1: Tests unitaires Jest
run_unit_tests() {
    start_phase "Tests Unitaires (Jest)"
    
    log "Ex√©cution des tests unitaires..."
    
    # Tests du wrapper API
    if npm test -- --testPathPattern=apiWrapper.test.ts --watchAll=false --verbose --silent; then
        success "Tests API Wrapper r√©ussis"
    else
        error "Tests API Wrapper √©chou√©s"
    fi
    
    # Tests du store
    if npm test -- --testPathPattern=adminStore.test.ts --watchAll=false --verbose --silent; then
        success "Tests Store Admin r√©ussis"
    else
        error "Tests Store Admin √©chou√©s"
    fi
    
    # Tests du hook
    if npm test -- --testPathPattern=useAPIData.test.tsx --watchAll=false --verbose --silent; then
        success "Tests Hook useAPIData r√©ussis"
    else
        error "Tests Hook useAPIData √©chou√©s"
    fi
}

# Phase 2: Tests d'int√©gration
run_integration_tests() {
    start_phase "Tests d'Int√©gration"
    
    log "Ex√©cution des tests d'int√©gration..."
    
    if npm test -- --testPathPattern=integration --watchAll=false --verbose --silent; then
        success "Tests d'int√©gration r√©ussis"
    else
        error "Tests d'int√©gration √©chou√©s"
    fi
}

# Phase 3: Build et validation
run_build_tests() {
    start_phase "Tests de Build"
    
    log "Construction de l'application..."
    
    if npm run build > build.log 2>&1; then
        success "Build r√©ussi"
        
        # V√©rifier la taille du build
        if [ -d "build" ]; then
            BUILD_SIZE=$(du -sh build/ | awk '{print $1}')
            success "Taille du build: $BUILD_SIZE"
            
            # V√©rifier les fichiers essentiels
            if [ -f "build/index.html" ] && [ -f "build/static/js/"*.js ]; then
                success "Fichiers essentiels pr√©sents"
            else
                error "Fichiers essentiels manquants dans le build"
            fi
        fi
    else
        error "Build √©chou√©"
        cat build.log
    fi
    
    rm -f build.log
}

# Phase 4: Tests du serveur
run_server_tests() {
    start_phase "Tests du Serveur"
    
    if [ ! -f "build/simple-server.py" ]; then
        warning "Serveur Python non trouv√© - cette phase sera ignor√©e"
        return
    fi
    
    log "D√©marrage du serveur Python en arri√®re-plan..."
    
    cd build
    python3 simple-server.py &
    SERVER_PID=$!
    cd ..
    
    # Attendre que le serveur d√©marre
    sleep 5
    
    # Tester la connectivit√© de base
    if curl -s -f http://localhost:3000 > /dev/null; then
        success "Serveur Python d√©marr√© avec succ√®s"
        
        # Ex√©cuter les tests de validation
        if command -v python3 &> /dev/null && python3 -c "import requests" 2>/dev/null; then
            log "Ex√©cution des tests de validation du serveur..."
            if python3 validate-server.py; then
                success "Validation du serveur r√©ussie"
            else
                error "Validation du serveur √©chou√©e"
            fi
        else
            warning "Module requests Python non disponible - tests d√©taill√©s ignor√©s"
        fi
    else
        error "Impossible de se connecter au serveur Python"
    fi
    
    # Arr√™ter le serveur
    if [ ! -z "$SERVER_PID" ]; then
        kill $SERVER_PID 2>/dev/null
        log "Serveur Python arr√™t√©"
    fi
}

# Phase 5: Tests de coverage
run_coverage_tests() {
    start_phase "Analyse de Couverture"
    
    log "G√©n√©ration du rapport de couverture..."
    
    if npm run test:coverage > coverage.log 2>&1; then
        success "Rapport de couverture g√©n√©r√©"
        
        # Extraire les m√©triques de couverture
        if [ -f "coverage/lcov-report/index.html" ]; then
            success "Rapport HTML disponible: coverage/lcov-report/index.html"
        fi
        
        # Afficher un r√©sum√©
        grep -A 10 "All files" coverage.log | head -5 || true
        
    else
        error "G√©n√©ration du rapport de couverture √©chou√©e"
        cat coverage.log
    fi
    
    rm -f coverage.log
}

# Phase 6: Tests manuels automatis√©s
run_automated_manual_tests() {
    start_phase "Tests Manuels Automatis√©s"
    
    info "V√©rification de la checklist des tests manuels..."
    
    # V√©rifier que les fichiers de test existent
    if [ -f "MANUAL_TESTS.md" ]; then
        success "Guide de tests manuels disponible"
    else
        warning "Guide de tests manuels manquant"
    fi
    
    if [ -f "test-admin.html" ] || [ -f "build/test-admin.html" ]; then
        success "Page de test automatique disponible"
    else
        warning "Page de test automatique manquante"
    fi
    
    # Compter les tests disponibles
    TEST_COUNT=$(find src/tests -name "*.test.*" 2>/dev/null | wc -l)
    success "$TEST_COUNT fichiers de test trouv√©s"
    
    info "Pour les tests manuels, consultez MANUAL_TESTS.md"
}

# R√©sum√© final
show_summary() {
    echo ""
    echo "üìä R√âSUM√â GLOBAL"
    echo "================"
    
    if [ "$OVERALL_SUCCESS" = true ]; then
        echo -e "${GREEN}üéâ TOUS LES TESTS AUTOMATIQUES SONT PASS√âS!${NC}"
        echo ""
        echo -e "${GREEN}‚ú® Votre application Metalyzr est valid√©e${NC}"
        echo ""
        echo "üöÄ Prochaines √©tapes:"
        echo "   1. Ex√©cuter les tests manuels (voir MANUAL_TESTS.md)"
        echo "   2. D√©marrer l'application: ./start-fixed.sh"
        echo "   3. Tester dans le navigateur:"
        echo "      - http://localhost:3000 (Dashboard)"
        echo "      - http://localhost:3000/admin (Admin)"
        echo "      - http://localhost:3000/test-admin.html (Tests)"
        echo ""
        echo -e "${BLUE}üìö Documentation disponible:${NC}"
        echo "   - QUICK_FIX_GUIDE.md : Guide technique"
        echo "   - MANUAL_TESTS.md : Tests manuels"
        echo "   - coverage/lcov-report/index.html : Couverture de code"
        
    else
        echo -e "${RED}‚ùå DES TESTS ONT √âCHOU√â${NC}"
        echo ""
        echo -e "${YELLOW}üîß Actions recommand√©es:${NC}"
        echo "   1. V√©rifier les erreurs ci-dessus"
        echo "   2. Corriger les probl√®mes identifi√©s"
        echo "   3. Relancer ce script"
        echo ""
        echo -e "${BLUE}üí° Aide au d√©bogage:${NC}"
        echo "   - V√©rifier les logs de build"
        echo "   - Consulter la documentation"
        echo "   - Tester les composants individuellement"
    fi
}

# Nettoyage
cleanup() {
    log "Nettoyage des processus temporaires..."
    
    # Tuer les serveurs qui pourraient encore tourner
    pkill -f "simple-server.py" 2>/dev/null || true
    pkill -f "react-scripts" 2>/dev/null || true
    
    # Nettoyer les fichiers temporaires
    rm -f build.log coverage.log test.log
    
    log "Nettoyage termin√©"
}

# Handler de signal pour nettoyage
trap cleanup EXIT

# EXECUTION PRINCIPALE
main() {
    # V√©rifier l'environnement
    check_environment
    
    # Ex√©cuter toutes les phases
    run_unit_tests
    run_integration_tests  
    run_build_tests
    run_server_tests
    run_coverage_tests
    run_automated_manual_tests
    
    # Afficher le r√©sum√©
    show_summary
    
    # Code de sortie bas√© sur le succ√®s global
    if [ "$OVERALL_SUCCESS" = true ]; then
        exit 0
    else
        exit 1
    fi
}

# Lancer le script principal
main "$@" 