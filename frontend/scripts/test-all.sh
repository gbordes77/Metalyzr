#!/bin/bash

echo "üß™ METALYZR - Suite de Tests Compl√®te"
echo "====================================="

# Couleurs pour les logs
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Variables
TOTAL_TESTS=0
PASSED_TESTS=0
FAILED_TESTS=0
TEST_RESULTS=()

# Fonction pour logger
log() {
    echo -e "${BLUE}[$(date +'%H:%M:%S')]${NC} $1"
}

success() {
    echo -e "${GREEN}‚úÖ $1${NC}"
    ((PASSED_TESTS++))
}

error() {
    echo -e "${RED}‚ùå $1${NC}"
    ((FAILED_TESTS++))
}

warning() {
    echo -e "${YELLOW}‚ö†Ô∏è  $1${NC}"
}

# V√©rifier qu'on est dans le bon r√©pertoire
if [ ! -f "package.json" ]; then
    error "package.json non trouv√©. Ex√©cutez ce script depuis le dossier frontend/"
    exit 1
fi

log "V√©rification de l'environnement de test..."

# V√©rifier que Jest est install√©
if ! npm list --depth=0 | grep -q "react-scripts"; then
    error "react-scripts non trouv√©. Installation des d√©pendances..."
    npm install
fi

echo ""
echo "üî¨ Phase 1: Tests Unitaires"
echo "========================="

# Tests du wrapper API
log "Test du wrapper API..."
((TOTAL_TESTS++))
if npm test -- --testPathPattern=apiWrapper.test.ts --watchAll=false --verbose; then
    success "Wrapper API: Tous les tests pass√©s"
    TEST_RESULTS+=("‚úÖ API Wrapper")
else
    error "Wrapper API: √âchec des tests"
    TEST_RESULTS+=("‚ùå API Wrapper")
fi

# Tests du store Zustand
log "Test du store Zustand..."
((TOTAL_TESTS++))
if npm test -- --testPathPattern=adminStore.test.ts --watchAll=false --verbose; then
    success "Store Admin: Tous les tests pass√©s"
    TEST_RESULTS+=("‚úÖ Store Admin")
else
    error "Store Admin: √âchec des tests"
    TEST_RESULTS+=("‚ùå Store Admin")
fi

# Tests du hook useAPIData
log "Test du hook useAPIData..."
((TOTAL_TESTS++))
if npm test -- --testPathPattern=useAPIData.test.tsx --watchAll=false --verbose; then
    success "Hook useAPIData: Tous les tests pass√©s"
    TEST_RESULTS+=("‚úÖ Hook useAPIData")
else
    error "Hook useAPIData: √âchec des tests"
    TEST_RESULTS+=("‚ùå Hook useAPIData")
fi

echo ""
echo "üîó Phase 2: Tests d'Int√©gration"
echo "==============================="

# Tests d'int√©gration du dashboard admin
log "Test d'int√©gration du dashboard admin..."
((TOTAL_TESTS++))
if npm test -- --testPathPattern=adminDashboard.integration.test.tsx --watchAll=false --verbose; then
    success "Dashboard Admin: Int√©gration r√©ussie"
    TEST_RESULTS+=("‚úÖ Dashboard Integration")
else
    error "Dashboard Admin: √âchec de l'int√©gration"
    TEST_RESULTS+=("‚ùå Dashboard Integration")
fi

echo ""
echo "üèóÔ∏è  Phase 3: Tests de Build"
echo "========================="

# Test de build
log "Test de construction de l'application..."
((TOTAL_TESTS++))
if npm run build > /dev/null 2>&1; then
    success "Build: Construction r√©ussie"
    TEST_RESULTS+=("‚úÖ Build Process")
else
    error "Build: √âchec de la construction"
    TEST_RESULTS+=("‚ùå Build Process")
fi

# V√©rifier la taille des bundles
if [ -d "build/static/js" ]; then
    JS_SIZE=$(du -sh build/static/js/*.js 2>/dev/null | awk '{sum += $1} END {print sum "K"}')
    CSS_SIZE=$(du -sh build/static/css/*.css 2>/dev/null | awk '{sum += $1} END {print sum "K"}')
    log "Taille des bundles: JS=${JS_SIZE}, CSS=${CSS_SIZE}"
fi

echo ""
echo "üåê Phase 4: Tests Fonctionnels"
echo "=============================="

# Test de d√©marrage du serveur de d√©veloppement
log "Test du serveur de d√©veloppement..."
((TOTAL_TESTS++))

# D√©marrer le serveur en arri√®re-plan
PORT=3001 BROWSER=none npm start > /dev/null 2>&1 &
SERVER_PID=$!
sleep 10

# Tester la connectivit√©
if curl -s -f http://localhost:3001 > /dev/null; then
    success "Serveur de dev: D√©marrage r√©ussi"
    TEST_RESULTS+=("‚úÖ Dev Server")
else
    error "Serveur de dev: √âchec du d√©marrage"
    TEST_RESULTS+=("‚ùå Dev Server")
fi

# Arr√™ter le serveur
kill $SERVER_PID 2>/dev/null

# Test du serveur Python (si le build existe)
if [ -f "build/simple-server.py" ]; then
    log "Test du serveur Python..."
    ((TOTAL_TESTS++))
    
    cd build
    python3 simple-server.py &
    PYTHON_PID=$!
    sleep 5
    
    if curl -s -f http://localhost:3000 > /dev/null; then
        success "Serveur Python: D√©marrage r√©ussi"
        TEST_RESULTS+=("‚úÖ Python Server")
    else
        error "Serveur Python: √âchec du d√©marrage"
        TEST_RESULTS+=("‚ùå Python Server")
    fi
    
    kill $PYTHON_PID 2>/dev/null
    cd ..
fi

echo ""
echo "üß™ Phase 5: Tests de l'API Mock"
echo "==============================="

# Tests des mocks
log "Test des handlers mock..."
((TOTAL_TESTS++))

cat << 'EOF' > /tmp/test-mock.js
const { mockHandlers, setupMockAPI } = require('./src/api/mockHandlers.ts');

// Test simple des mocks
const testMocks = () => {
    try {
        // V√©rifier que les mocks sont d√©finis
        if (!mockHandlers['/api/stats']) throw new Error('Mock stats manquant');
        if (!mockHandlers['/health']) throw new Error('Mock health manquant');
        
        // V√©rifier la structure des donn√©es
        const stats = mockHandlers['/api/stats'];
        if (typeof stats.tournaments !== 'number') throw new Error('Stats tournaments invalide');
        
        console.log('‚úÖ Mocks API: Validation r√©ussie');
        process.exit(0);
    } catch (error) {
        console.log('‚ùå Mocks API: ' + error.message);
        process.exit(1);
    }
};

testMocks();
EOF

if node /tmp/test-mock.js 2>/dev/null; then
    success "Mocks API: Validation r√©ussie"
    TEST_RESULTS+=("‚úÖ API Mocks")
else
    error "Mocks API: Validation √©chou√©e"
    TEST_RESULTS+=("‚ùå API Mocks")
fi

rm -f /tmp/test-mock.js

echo ""
echo "üöÄ Phase 6: Tests de Performance"
echo "==============================="

# Test de la taille des bundles
if [ -d "build" ]; then
    log "Analyse de la taille des bundles..."
    ((TOTAL_TESTS++))
    
    TOTAL_SIZE=$(du -sh build/ | awk '{print $1}')
    log "Taille totale du build: $TOTAL_SIZE"
    
    # V√©rifier que le build n'est pas trop gros (< 50MB)
    SIZE_MB=$(du -sm build/ | awk '{print $1}')
    if [ "$SIZE_MB" -lt 50 ]; then
        success "Taille du build: Acceptable ($TOTAL_SIZE)"
        TEST_RESULTS+=("‚úÖ Bundle Size")
    else
        warning "Taille du build: Importante ($TOTAL_SIZE)"
        TEST_RESULTS+=("‚ö†Ô∏è  Bundle Size")
    fi
fi

echo ""
echo "üìä R√âSUM√â DES TESTS"
echo "=================="

echo ""
echo "R√©sultats d√©taill√©s:"
for result in "${TEST_RESULTS[@]}"; do
    echo "  $result"
done

echo ""
echo -e "Total: ${BLUE}$TOTAL_TESTS${NC} tests"
echo -e "R√©ussis: ${GREEN}$PASSED_TESTS${NC}"
echo -e "√âchou√©s: ${RED}$FAILED_TESTS${NC}"

PERCENT=$((PASSED_TESTS * 100 / TOTAL_TESTS))
echo -e "Taux de r√©ussite: ${BLUE}${PERCENT}%${NC}"

echo ""
if [ $FAILED_TESTS -eq 0 ]; then
    echo -e "${GREEN}üéâ TOUS LES TESTS SONT PASS√âS!${NC}"
    echo -e "${GREEN}‚ú® Votre application Metalyzr est pr√™te pour la production${NC}"
    exit 0
else
    echo -e "${YELLOW}‚ö†Ô∏è  $FAILED_TESTS test(s) ont √©chou√©${NC}"
    echo -e "${YELLOW}üîß Veuillez corriger les probl√®mes avant de d√©ployer${NC}"
    exit 1
fi 